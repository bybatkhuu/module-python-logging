{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p><code>beans-logging</code> is a python package for simple logger and easily managing logs.</p> <p>It is a <code>Loguru</code> based custom logging package for python projects.</p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>Main logger based on Loguru logging - https://pypi.org/project/loguru</li> <li>Logging to log files (all, error, json)</li> <li>Pre-defined logging configs and handlers</li> <li>Colorful logging</li> <li>Auto intercepting and muting modules</li> <li>Load config from YAML or JSON file</li> <li>Custom options as a config</li> <li>Custom logging formats</li> <li>Multiprocess compatibility (Linux, macOS - 'fork')</li> <li>Add custom handlers</li> <li>Base logging module</li> </ul>"},{"location":"release-notes/","title":"\ud83d\udccc Release Notes","text":""},{"location":"release-notes/#v602-2025-10-01","title":"v6.0.2 (2025-10-01)","text":""},{"location":"release-notes/#whats-changed","title":"What's Changed","text":""},{"location":"release-notes/#fixes","title":"\ud83d\udc1b Fixes","text":"<ul> <li>fix: remove unnecessary UTF-8 encoding declarations and improve type \u2026 by @bybatkhuu in https://github.com/bybatkhuu/module-python-logging/pull/30</li> </ul> <p>Full Changelog: https://github.com/bybatkhuu/module-python-logging/compare/v6.0.1...v6.0.2</p>"},{"location":"release-notes/#v601-2025-10-01","title":"v6.0.1 (2025-10-01)","text":""},{"location":"release-notes/#whats-changed_1","title":"What's Changed","text":""},{"location":"release-notes/#breaking-changes","title":"\ud83d\udca5 Breaking Changes","text":"<ul> <li>BREAKING CHANGES!: refactor setup.py to pyproject.toml and many more \u2026 by @bybatkhuu in https://github.com/bybatkhuu/module-python-logging/pull/29</li> </ul> <p>Full Changelog: https://github.com/bybatkhuu/module-python-logging/compare/v6.0.0...v6.0.1</p>"},{"location":"about/authors/","title":"\ud83e\uddd9\u200d\u2642\ufe0f Authors","text":"<p>This project is developed by the following authors:</p> <ul> <li>@bybatkhuu - Batkhuu Byambajav</li> </ul>","tags":["about"]},{"location":"about/contact/","title":"\ud83d\udcde Contact","text":"<p>You can contact me by email at batkhuu10@gmail.com.</p>","tags":["about"]},{"location":"about/faq/","title":"\u2753 FAQ","text":"<p>This section contains frequently asked questions about this project.</p>","tags":["about"]},{"location":"about/faq/#q1-how-do-i-get-started-with-this-project","title":"Q1: How do I get started with this project?","text":"<p>To get started with this project, follow the instructions in the Getting Started guide.</p>","tags":["about"]},{"location":"about/license/","title":"\u00a9\ufe0f License","text":"<p>This project is licensed as the <code>LICENSE.md</code> file for details.</p>","tags":["about"]},{"location":"api-docs/LoggerLoader/","title":"LoggerLoader","text":"<p>LoggerLoader class for setting up loguru logger.</p> <p>Attributes:</p> Name Type Description <code>_CONFIG_FILE_PATH</code> <code>str</code> <p>Default logger config file path. Defaults to '${PWD}/configs/logger.yml'.</p> <code>handlers_map</code> <code>     (dict          </code> <p>Registered logger handlers map as dictionary. Defaults to None.</p> <code>config</code> <code>           (LoggerConfigPM</code> <p>Logger config as . Defaults to None. <code>config_file_path</code> <code> (str           </code> <p>Logger config file path. Defaults to <code>LoggerLoader._CONFIG_FILE_PATH</code>.</p> <p>Methods:</p> Name Description <code>load</code> <p>Load logger handlers based on logger config.</p> <code>remove_handler</code> <p>Remove all handlers or specific handler by name or id from logger.</p> <code>update_config</code> <p>Update logger config with new config.</p> <code>_load_env_vars</code> <p>Load 'BEANS_LOGGING_CONFIG_PATH' environment variable for logger config file path.</p> <code>_load_config_file</code> <p>Load logger config from file.</p> <code>_check_env</code> <p>Check environment variables for logger config.</p> <code>_check_config</code> <p>Check logger config to update some options before loading handlers.</p> <code>_add_stream_std_handler</code> <p>Add std stream handler to logger.</p> <code>_add_file_log_handler</code> <p>Add log file handler to logger.</p> <code>_add_file_err_handler</code> <p>Add error log file handler to logger.</p> <code>_add_file_json_handler</code> <p>Add json log file handler to logger.</p> <code>_add_file_json_err_handler</code> <p>Add json error log file handler to logger.</p> <code>add_custom_handler</code> <p>Add custom handler to logger.</p> <code>_load_intercept_handlers</code> <p>Load intercept handlers to catch third-pary modules log or mute them.</p> Source code in <code>src/beans_logging/_base.py</code> <pre><code>class LoggerLoader:\n    \"\"\"LoggerLoader class for setting up loguru logger.\n\n    Attributes:\n        _CONFIG_FILE_PATH (str           ): Default logger config file path. Defaults to '${PWD}/configs/logger.yml'.\n\n        handlers_map      (dict          ): Registered logger handlers map as dictionary. Defaults to None.\n        config            (LoggerConfigPM): Logger config as &lt;class 'LoggerConfigPM'&gt;. Defaults to None.\n        config_file_path  (str           ): Logger config file path. Defaults to `LoggerLoader._CONFIG_FILE_PATH`.\n\n    Methods:\n        load()                      : Load logger handlers based on logger config.\n        remove_handler()            : Remove all handlers or specific handler by name or id from logger.\n        update_config()             : Update logger config with new config.\n        _load_env_vars()            : Load 'BEANS_LOGGING_CONFIG_PATH' environment variable for logger config file path.\n        _load_config_file()         : Load logger config from file.\n        _check_env()                : Check environment variables for logger config.\n        _check_config()             : Check logger config to update some options before loading handlers.\n        _add_stream_std_handler()   : Add std stream handler to logger.\n        _add_file_log_handler()     : Add log file handler to logger.\n        _add_file_err_handler()     : Add error log file handler to logger.\n        _add_file_json_handler()    : Add json log file handler to logger.\n        _add_file_json_err_handler(): Add json error log file handler to logger.\n        add_custom_handler()        : Add custom handler to logger.\n        _load_intercept_handlers()  : Load intercept handlers to catch third-pary modules log or mute them.\n    \"\"\"\n\n    _CONFIG_FILE_PATH = os.path.join(os.getcwd(), \"configs\", \"logger.yml\")\n\n    @validate_call\n    def __init__(\n        self,\n        config: LoggerConfigPM | dict[str, Any] | None = None,\n        config_file_path: str = _CONFIG_FILE_PATH,\n        auto_config_file: bool = True,\n        auto_load: bool = False,\n    ):\n        \"\"\"LoggerLoader constructor method.\n\n        Args:\n            config           (LoggerConfigPM | dict | None], optional): New logger config to update loaded config.\n                                                                            Defaults to None.\n            config_file_path (str                          , optional): Logger config file path. Defaults to\n                                                                            `LoggerLoader._CONFIG_FILE_PATH`.\n            auto_config_file (bool                         , optional): Indicates whether to load logger config\n                                                                            file or not. Defaults to True.\n            auto_load        (bool                         , optional): Indicates whether to load logger\n                                                                            handlers or not. Defaults to False.\n        \"\"\"\n\n        self.handlers_map = {\"default\": 0}\n        self.config = LoggerConfigPM()\n        if config:\n            self.update_config(config=config)\n        self.config_file_path = config_file_path\n\n        self._load_env_vars()\n\n        if auto_config_file:\n            self._load_config_file()\n\n        if auto_load:\n            self.load()\n\n    def load(self) -&gt; Logger:\n        \"\"\"Load logger handlers based on logger config.\n\n        Returns:\n            Logger: Main loguru logger instance.\n        \"\"\"\n\n        self.remove_handler()\n\n        self._check_env()\n        self._check_config()\n\n        if self.config.stream.std_handler.enabled:\n            self._add_stream_std_handler()\n\n        if self.config.file.log_handlers.enabled:\n            self._add_file_log_handler()\n            self._add_file_err_handler()\n\n        if self.config.file.json_handlers.enabled:\n            self._add_file_json_handler()\n            self._add_file_json_err_handler()\n\n        self._load_intercept_handlers()\n\n        return logger\n\n    @validate_call\n    def remove_handler(self, handler: str | None = None, handler_type: str = \"NAME\"):\n        \"\"\"Remove all handlers or specific handler by name or id from logger.\n\n        Raises:\n            ValueError: The `handler_type` argument value '{handler_type}' is invalid, must be 'NAME' or 'ID'!\n\n        Args:\n            handler      (str, optional): Handler name or id to remove. Defaults to None.\n            handler_type (int, optional): Handler type to remove, must be 'NAME' or 'ID'. Defaults to 'name'.\n        \"\"\"\n\n        if handler:\n            handler_type = handler_type.strip().upper()\n            if handler_type == \"NAME\":\n                if handler in self.handlers_map:\n                    _handler_id = self.handlers_map[handler]\n                    logger.remove(_handler_id)\n                    self.handlers_map.pop(handler)\n                    return\n            elif handler_type == \"ID\":\n                if handler in self.handlers_map.values():\n                    logger.remove(handler)\n                    for _handler_name, _handler_id in self.handlers_map.items():\n                        if handler == _handler_id:\n                            self.handlers_map.pop(_handler_name)\n                    return\n            else:\n                raise ValueError(\n                    f\"`handler_type` argument value '{handler_type}' is invalid, must be 'NAME' or 'ID'!\"\n                )\n\n        logger.remove()\n        self.handlers_map.clear()\n\n    @validate_call\n    def update_config(self, config: LoggerConfigPM | dict[str, Any]):\n        \"\"\"Update logger config with new config.\n\n        Args:\n            config (Union[LoggerConfigPM, dict], required): New logger config to update loaded config.\n\n        Raises:\n            Exception: Failed to load `config` argument into &lt;class 'LoggerConfigPM'&gt;.\n        \"\"\"\n\n        if isinstance(config, dict):\n            if \"2.0.0\" &lt;= pydantic.__version__:\n                _config_dict = self.config.model_dump()\n            else:\n                _config_dict = self.config.dict()\n\n            _merged_dict = deep_merge(_config_dict, config)\n            try:\n                self.config = LoggerConfigPM(**_merged_dict)\n            except Exception:\n                logger.critical(\n                    \"Failed to load `config` argument into &lt;class 'LoggerConfigPM'&gt;.\"\n                )\n                raise\n\n        elif isinstance(config, LoggerConfigPM):\n            self.config = config\n\n    def _load_env_vars(self):\n        \"\"\"Load 'BEANS_LOGGING_CONFIG_PATH' environment variable for logger config file path.\"\"\"\n\n        _env_config_file_path = os.getenv(\"BEANS_LOGGING_CONFIG_PATH\")\n        if _env_config_file_path:\n            try:\n                self.config_file_path = _env_config_file_path\n            except Exception:\n                logger.warning(\n                    \"Failed to load 'BEANS_LOGGING_CONFIG_PATH' environment variable!\"\n                )\n\n    def _load_config_file(self):\n        \"\"\"Load logger config from file.\"\"\"\n\n        _file_format = \"\"\n        if self.config_file_path.lower().endswith((\".yml\", \".yaml\")):\n            _file_format = \"YAML\"\n        if self.config_file_path.lower().endswith(\".json\"):\n            _file_format = \"JSON\"\n        # elif self.config_file_path.lower().endswith(\".toml\"):\n        #     _file_format = \"TOML\"\n\n        # Loading config from file, if it's exits:\n        if os.path.isfile(self.config_file_path):\n            if _file_format == \"YAML\":\n                try:\n                    with open(self.config_file_path, encoding=\"utf-8\") as _config_file:\n                        _new_config_dict = yaml.safe_load(_config_file) or {}\n                        if \"logger\" not in _new_config_dict:\n                            logger.warning(\n                                f\"'{self.config_file_path}' YAML config file doesn't have 'logger' section!\"\n                            )\n                            return\n\n                        _new_config_dict = _new_config_dict[\"logger\"]\n                        if \"2.0.0\" &lt;= pydantic.__version__:\n                            _config_dict = self.config.model_dump()\n                        else:\n                            _config_dict = self.config.dict()\n\n                        _merged_dict = deep_merge(_config_dict, _new_config_dict)\n                        self.config = LoggerConfigPM(**_merged_dict)\n                except Exception:\n                    logger.critical(\n                        f\"Failed to load '{self.config_file_path}' yaml config file.\"\n                    )\n                    raise\n            elif _file_format == \"JSON\":\n                try:\n                    with open(self.config_file_path, encoding=\"utf-8\") as _config_file:\n                        _new_config_dict = json.load(_config_file) or {}\n                        if \"logger\" not in _new_config_dict:\n                            logger.warning(\n                                f\"'{self.config_file_path}' JSON config file doesn't have 'logger' section!\"\n                            )\n                            return\n\n                        _new_config_dict = _new_config_dict[\"logger\"]\n                        if \"2.0.0\" &lt;= pydantic.__version__:\n                            _config_dict = self.config.model_dump()\n                        else:\n                            _config_dict = self.config.dict()\n\n                        _merged_dict = deep_merge(_config_dict, _new_config_dict)\n                        self.config = LoggerConfigPM(**_merged_dict)\n                except Exception:\n                    logger.critical(\n                        f\"Failed to load '{self.config_file_path}' json config file.\"\n                    )\n                    raise\n            # elif _file_format == \"TOML\":\n            #     try:\n            #         import toml\n\n            #         with open(\n            #             self.config_file_path, \"r\", encoding=\"utf-8\"\n            #         ) as _config_file:\n            #             _new_config_dict = toml.load(_config_file) or {}\n            #             if \"logger\" not in _new_config_dict:\n            #                 logger.warning(\n            #                     f\"'{self.config_file_path}' TOML config file doesn't have 'logger' section!\"\n            #                 )\n            #                 return\n\n            #             _new_config_dict = _new_config_dict[\"logger\"]\n            #             if \"2.0.0\" &lt;= pydantic.__version__:\n            #                 _config_dict = self.config.model_dump()\n            #             else:\n            #                 _config_dict = self.config.dict()\n\n            #             _merged_dict = deep_merge(_config_dict, _new_config_dict)\n            #             self.config = LoggerConfigPM(**_merged_dict)\n            #     except Exception:\n            #         logger.critical(\n            #             f\"Failed to load '{self.config_file_path}' toml config file.\"\n            #         )\n            #         raise\n\n    def _check_env(self):\n        \"\"\"Check environment variables for logger config.\"\"\"\n\n        # Checking environment for DEBUG option:\n        _is_debug = False\n        _ENV = str(os.getenv(\"ENV\")).strip().lower()\n        _DEBUG = str(os.getenv(\"DEBUG\")).strip().lower()\n        if (\n            (_DEBUG == \"true\")\n            or (_DEBUG == \"1\")\n            or ((_ENV == \"development\") and ((_DEBUG == \"none\") or (_DEBUG == \"\")))\n        ):\n            _is_debug = True\n\n        if _is_debug and (self.config.level != \"TRACE\"):\n            self.config.level = \"DEBUG\"\n\n        if \"BEANS_LOGGING_LOGS_DIR\" in os.environ:\n            self.config.file.logs_dir = os.getenv(\"BEANS_LOGGING_LOGS_DIR\")\n\n        # if self.config.stream.use_color:\n        #     # Checking terminal could support xterm colors:\n        #     _TERM = str(os.getenv(\"TERM\")).strip()\n        #     if not \"xterm\" in _TERM:\n        #         self.config.stream.use_color = False\n\n    def _check_config(self):\n        \"\"\"Check logger config to update some options before loading handlers.\"\"\"\n\n        if self.config.level == \"TRACE\":\n            self.config.use_diagnose = True\n\n        if self.config.stream.use_icon:\n            self.config.stream.format_str = self.config.stream.format_str.replace(\n                \"level_short:&lt;5\", \"level.icon:&lt;4\"\n            )\n\n        if not os.path.isabs(self.config.file.logs_dir):\n            self.config.file.logs_dir = os.path.join(\n                os.getcwd(), self.config.file.logs_dir\n            )\n\n        if \"{app_name}\" in self.config.file.log_handlers.log_path:\n            self.config.file.log_handlers.log_path = (\n                self.config.file.log_handlers.log_path.format(\n                    app_name=self.config.app_name\n                )\n            )\n\n        if \"{app_name}\" in self.config.file.log_handlers.err_path:\n            self.config.file.log_handlers.err_path = (\n                self.config.file.log_handlers.err_path.format(\n                    app_name=self.config.app_name\n                )\n            )\n\n        if \"{app_name}\" in self.config.file.json_handlers.log_path:\n            self.config.file.json_handlers.log_path = (\n                self.config.file.json_handlers.log_path.format(\n                    app_name=self.config.app_name\n                )\n            )\n\n        if \"{app_name}\" in self.config.file.json_handlers.err_path:\n            self.config.file.json_handlers.err_path = (\n                self.config.file.json_handlers.err_path.format(\n                    app_name=self.config.app_name\n                )\n            )\n\n    def _add_stream_std_handler(self) -&gt; int:\n        \"\"\"Add std stream handler to logger.\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        return self.add_custom_handler(handler_name=\"STREAM.STD\", filter=use_std_filter)\n\n    def _add_file_log_handler(self) -&gt; int:\n        \"\"\"Add log file handler to logger.\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        return self.add_custom_handler(handler_name=\"FILE\", filter=use_file_filter)\n\n    def _add_file_err_handler(self) -&gt; int:\n        \"\"\"Add error log file handler to logger.\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        _handler_id = self.add_custom_handler(\n            handler_name=\"FILE_ERR\",\n            sink=self.config.file.log_handlers.err_path,\n            level=\"WARNING\",\n            filter=use_file_err_filter,\n        )\n        return _handler_id\n\n    def _add_file_json_handler(self) -&gt; int:\n        \"\"\"Add json log file handler to logger.\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        _kwargs = {\n            \"sink\": self.config.file.json_handlers.log_path,\n            \"filter\": use_file_json_filter,\n            \"serialize\": True,\n        }\n        if self.config.file.json_handlers.use_custom:\n            _kwargs[\"format\"] = json_format\n            _kwargs[\"serialize\"] = False\n\n        _handler_id = self.add_custom_handler(handler_name=\"FILE.JSON\", **_kwargs)\n        return _handler_id\n\n    def _add_file_json_err_handler(self) -&gt; int:\n        \"\"\"Add json error log file handler to logger.\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        _kwargs = {\n            \"sink\": self.config.file.json_handlers.err_path,\n            \"level\": \"WARNING\",\n            \"filter\": use_file_json_err_filter,\n            \"serialize\": True,\n        }\n        if self.config.file.json_handlers.use_custom:\n            _kwargs[\"format\"] = json_format\n            _kwargs[\"serialize\"] = False\n\n        _handler_id = self.add_custom_handler(\n            handler_name=\"FILE.JSON_ERR\",\n            **_kwargs,\n        )\n        return _handler_id\n\n    @validate_call\n    def add_custom_handler(self, handler_name: str, **kwargs) -&gt; int:\n        \"\"\"Add custom handler to logger.\n\n        Args:\n            handler_name (str): Handler name/type to add logger.\n\n        Raises:\n            ValueError: Custom handler '{handler_name}' already exists in logger!\n            ValueError: The `sink` argument is required for custom handler!\n\n        Returns:\n            int: Handler id.\n        \"\"\"\n\n        if handler_name in self.handlers_map:\n            raise ValueError(\n                f\"Custom handler '{handler_name}' already exists in logger!\"\n            )\n\n        _handler_id = None\n        try:\n            handler_name = handler_name.strip().upper()\n\n            if \"level\" not in kwargs:\n                kwargs[\"level\"] = self.config.level\n\n            if \"filter\" not in kwargs:\n                kwargs[\"filter\"] = use_all_filter\n\n            if \"backtrace\" not in kwargs:\n                kwargs[\"backtrace\"] = self.config.use_backtrace\n\n            if \"diagnose\" not in kwargs:\n                kwargs[\"diagnose\"] = self.config.use_diagnose\n\n            if handler_name.startswith(\"STREAM\"):\n                if \"sink\" not in kwargs:\n                    kwargs[\"sink\"] = std_sink\n\n                if \"format\" not in kwargs:\n                    kwargs[\"format\"] = self.config.stream.format_str\n\n                if \"colorize\" not in kwargs:\n                    kwargs[\"colorize\"] = self.config.stream.use_color\n            elif handler_name.startswith(\"FILE\"):\n                kwargs[\"enqueue\"] = True\n\n                if \"sink\" not in kwargs:\n                    kwargs[\"sink\"] = self.config.file.log_handlers.log_path\n\n                if isinstance(kwargs[\"sink\"], str):\n                    _log_path = kwargs[\"sink\"]\n                    if not os.path.isabs(_log_path):\n                        _log_path = os.path.abspath(\n                            os.path.join(self.config.file.logs_dir, _log_path)\n                        )\n\n                    if \"{app_name}\" in _log_path:\n                        _log_path = _log_path.format(app_name=self.config.app_name)\n\n                    _logs_dir, _ = os.path.split(_log_path)\n                    create_dir(create_dir=_logs_dir)\n                    kwargs[\"sink\"] = _log_path\n\n                if \"format\" not in kwargs:\n                    kwargs[\"format\"] = self.config.file.log_handlers.format_str\n\n                if \"rotation\" not in kwargs:\n                    kwargs[\"rotation\"] = RotationChecker(\n                        rotate_size=self.config.file.rotate_size,\n                        rotate_time=self.config.file.rotate_time,\n                    ).should_rotate\n\n                if \"retention\" not in kwargs:\n                    kwargs[\"retention\"] = self.config.file.backup_count\n\n                if \"encoding\" not in kwargs:\n                    kwargs[\"encoding\"] = self.config.file.encoding\n\n            if \"sink\" not in kwargs:\n                raise ValueError(\n                    f\"`sink` argument is required for custom handler '{handler_name}'!\"\n                )\n\n            _handler_id = logger.add(**kwargs)\n        except Exception:\n            logger.critical(f\"Failed to add custom handler '{handler_name}' to logger!\")\n            raise\n\n        self.handlers_map[handler_name] = _handler_id\n        return _handler_id\n\n    def _load_intercept_handlers(self):\n        \"\"\"Load intercept handlers to catch third-pary modules log or mute them.\"\"\"\n\n        _intercept_handler = InterceptHandler()\n\n        # Intercepting all logs from standard (root logger) logging:\n        logging.basicConfig(handlers=[_intercept_handler], level=0, force=True)\n\n        _intercepted_modules = set()\n        _muted_modules = set()\n\n        if self.config.intercept.auto_load.enabled:\n            for _module_name in list(logging.root.manager.loggerDict.keys()):\n                if self.config.intercept.auto_load.only_base:\n                    _module_name = _module_name.split(\".\")[0]\n\n                if (_module_name not in _intercepted_modules) and (\n                    _module_name not in self.config.intercept.auto_load.ignore_modules\n                ):\n                    _logger = logging.getLogger(_module_name)\n                    _logger.handlers = [_intercept_handler]\n                    _logger.propagate = False\n                    _intercepted_modules.add(_module_name)\n\n        for _include_module_name in self.config.intercept.include_modules:\n            _logger = logging.getLogger(_include_module_name)\n            _logger.handlers = [_intercept_handler]\n            logger.propagate = False\n\n            if _include_module_name not in _intercepted_modules:\n                _intercepted_modules.add(_include_module_name)\n\n        for _mute_module_name in self.config.intercept.mute_modules:\n            _logger = logging.getLogger(_mute_module_name)\n            _logger.handlers = []\n            _logger.propagate = False\n            _logger.disabled = True\n\n            if _mute_module_name in _intercepted_modules:\n                _intercepted_modules.remove(_mute_module_name)\n\n            if _mute_module_name not in _muted_modules:\n                _muted_modules.add(_mute_module_name)\n\n        logger.trace(\n            f\"Intercepted modules: {list(_intercepted_modules)}; Muted modules: {list(_muted_modules)};\"\n        )\n\n    # ATTRIBUTES #\n    # handlers_map\n    @property\n    def handlers_map(self) -&gt; dict[str, int]:\n        try:\n            return self.__handlers_map\n        except AttributeError:\n            self.__handlers_map = {\"default\": 0}\n\n        return self.__handlers_map\n\n    @handlers_map.setter\n    def handlers_map(self, handlers_map: dict[str, int]):\n        if not isinstance(handlers_map, dict):\n            raise TypeError(\n                f\"`handlers_map` attribute type {type(handlers_map)} is invalid, must be &lt;dict&gt;!.\"\n            )\n\n        self.__handlers_map = copy.deepcopy(handlers_map)\n\n    # handlers_map\n\n    # config\n    @property\n    def config(self) -&gt; LoggerConfigPM:\n        try:\n            return self.__config\n        except AttributeError:\n            self.__config = LoggerConfigPM()\n\n        return self.__config\n\n    @config.setter\n    def config(self, config: LoggerConfigPM):\n        if not isinstance(config, LoggerConfigPM):\n            raise TypeError(\n                f\"`config` attribute type {type(config)} is invalid, must be a &lt;class 'LoggerConfigPM'&gt;!\"\n            )\n\n        self.__config = copy.deepcopy(config)\n\n    # config\n\n    # config_file_path\n    @property\n    def config_file_path(self) -&gt; str:\n        try:\n            return self.__config_file_path\n        except AttributeError:\n            self.__config_file_path = LoggerLoader._CONFIG_FILE_PATH\n\n        return self.__config_file_path\n\n    @config_file_path.setter\n    def config_file_path(self, config_file_path: str):\n        if not isinstance(config_file_path, str):\n            raise TypeError(\n                f\"`config_file_path` attribute type {type(config_file_path)} is invalid, must be a &lt;str&gt;!\"\n            )\n\n        config_file_path = config_file_path.strip()\n        if config_file_path == \"\":\n            raise ValueError(\"`config_file_path` attribute value is empty!\")\n\n        if (not config_file_path.lower().endswith((\".yml\", \".yaml\"))) and (\n            not config_file_path.lower().endswith(\".json\")\n        ):\n            if not config_file_path.lower().endswith(\".toml\"):\n                raise NotImplementedError(\n                    f\"`config_file_path` attribute value '{config_file_path}' is invalid, \"\n                    f\"TOML file format is not supported yet!\"\n                )\n\n            raise ValueError(\n                f\"`config_file_path` attribute value '{config_file_path}' is invalid, \"\n                f\"file must be '.yml', '.yaml' or '.json' format!\"\n            )\n\n        if not os.path.isabs(config_file_path):\n            config_file_path = os.path.join(os.getcwd(), config_file_path)\n\n        self.__config_file_path = config_file_path\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"api-docs/LoggerLoader/#src.beans_logging.LoggerLoader.__init__","title":"<code>__init__(config=None, config_file_path=_CONFIG_FILE_PATH, auto_config_file=True, auto_load=False)</code>","text":"<p>LoggerLoader constructor method.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>LoggerConfigPM | dict | None]</code> <p>New logger config to update loaded config.                                                             Defaults to None.</p> <code>None</code> <code>config_file_path</code> <code>str</code> <p>Logger config file path. Defaults to                                                             <code>LoggerLoader._CONFIG_FILE_PATH</code>.</p> <code>_CONFIG_FILE_PATH</code> <code>auto_config_file</code> <code>bool</code> <p>Indicates whether to load logger config                                                             file or not. Defaults to True.</p> <code>True</code> <code>auto_load</code> <code>bool</code> <p>Indicates whether to load logger                                                             handlers or not. Defaults to False.</p> <code>False</code> Source code in <code>src/beans_logging/_base.py</code> <pre><code>@validate_call\ndef __init__(\n    self,\n    config: LoggerConfigPM | dict[str, Any] | None = None,\n    config_file_path: str = _CONFIG_FILE_PATH,\n    auto_config_file: bool = True,\n    auto_load: bool = False,\n):\n    \"\"\"LoggerLoader constructor method.\n\n    Args:\n        config           (LoggerConfigPM | dict | None], optional): New logger config to update loaded config.\n                                                                        Defaults to None.\n        config_file_path (str                          , optional): Logger config file path. Defaults to\n                                                                        `LoggerLoader._CONFIG_FILE_PATH`.\n        auto_config_file (bool                         , optional): Indicates whether to load logger config\n                                                                        file or not. Defaults to True.\n        auto_load        (bool                         , optional): Indicates whether to load logger\n                                                                        handlers or not. Defaults to False.\n    \"\"\"\n\n    self.handlers_map = {\"default\": 0}\n    self.config = LoggerConfigPM()\n    if config:\n        self.update_config(config=config)\n    self.config_file_path = config_file_path\n\n    self._load_env_vars()\n\n    if auto_config_file:\n        self._load_config_file()\n\n    if auto_load:\n        self.load()\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"api-docs/LoggerLoader/#src.beans_logging.LoggerLoader.add_custom_handler","title":"<code>add_custom_handler(handler_name, **kwargs)</code>","text":"<p>Add custom handler to logger.</p> <p>Parameters:</p> Name Type Description Default <code>handler_name</code> <code>str</code> <p>Handler name/type to add logger.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Custom handler '{handler_name}' already exists in logger!</p> <code>ValueError</code> <p>The <code>sink</code> argument is required for custom handler!</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Handler id.</p> Source code in <code>src/beans_logging/_base.py</code> <pre><code>@validate_call\ndef add_custom_handler(self, handler_name: str, **kwargs) -&gt; int:\n    \"\"\"Add custom handler to logger.\n\n    Args:\n        handler_name (str): Handler name/type to add logger.\n\n    Raises:\n        ValueError: Custom handler '{handler_name}' already exists in logger!\n        ValueError: The `sink` argument is required for custom handler!\n\n    Returns:\n        int: Handler id.\n    \"\"\"\n\n    if handler_name in self.handlers_map:\n        raise ValueError(\n            f\"Custom handler '{handler_name}' already exists in logger!\"\n        )\n\n    _handler_id = None\n    try:\n        handler_name = handler_name.strip().upper()\n\n        if \"level\" not in kwargs:\n            kwargs[\"level\"] = self.config.level\n\n        if \"filter\" not in kwargs:\n            kwargs[\"filter\"] = use_all_filter\n\n        if \"backtrace\" not in kwargs:\n            kwargs[\"backtrace\"] = self.config.use_backtrace\n\n        if \"diagnose\" not in kwargs:\n            kwargs[\"diagnose\"] = self.config.use_diagnose\n\n        if handler_name.startswith(\"STREAM\"):\n            if \"sink\" not in kwargs:\n                kwargs[\"sink\"] = std_sink\n\n            if \"format\" not in kwargs:\n                kwargs[\"format\"] = self.config.stream.format_str\n\n            if \"colorize\" not in kwargs:\n                kwargs[\"colorize\"] = self.config.stream.use_color\n        elif handler_name.startswith(\"FILE\"):\n            kwargs[\"enqueue\"] = True\n\n            if \"sink\" not in kwargs:\n                kwargs[\"sink\"] = self.config.file.log_handlers.log_path\n\n            if isinstance(kwargs[\"sink\"], str):\n                _log_path = kwargs[\"sink\"]\n                if not os.path.isabs(_log_path):\n                    _log_path = os.path.abspath(\n                        os.path.join(self.config.file.logs_dir, _log_path)\n                    )\n\n                if \"{app_name}\" in _log_path:\n                    _log_path = _log_path.format(app_name=self.config.app_name)\n\n                _logs_dir, _ = os.path.split(_log_path)\n                create_dir(create_dir=_logs_dir)\n                kwargs[\"sink\"] = _log_path\n\n            if \"format\" not in kwargs:\n                kwargs[\"format\"] = self.config.file.log_handlers.format_str\n\n            if \"rotation\" not in kwargs:\n                kwargs[\"rotation\"] = RotationChecker(\n                    rotate_size=self.config.file.rotate_size,\n                    rotate_time=self.config.file.rotate_time,\n                ).should_rotate\n\n            if \"retention\" not in kwargs:\n                kwargs[\"retention\"] = self.config.file.backup_count\n\n            if \"encoding\" not in kwargs:\n                kwargs[\"encoding\"] = self.config.file.encoding\n\n        if \"sink\" not in kwargs:\n            raise ValueError(\n                f\"`sink` argument is required for custom handler '{handler_name}'!\"\n            )\n\n        _handler_id = logger.add(**kwargs)\n    except Exception:\n        logger.critical(f\"Failed to add custom handler '{handler_name}' to logger!\")\n        raise\n\n    self.handlers_map[handler_name] = _handler_id\n    return _handler_id\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"api-docs/LoggerLoader/#src.beans_logging.LoggerLoader.load","title":"<code>load()</code>","text":"<p>Load logger handlers based on logger config.</p> <p>Returns:</p> Name Type Description <code>Logger</code> <code>Logger</code> <p>Main loguru logger instance.</p> Source code in <code>src/beans_logging/_base.py</code> <pre><code>def load(self) -&gt; Logger:\n    \"\"\"Load logger handlers based on logger config.\n\n    Returns:\n        Logger: Main loguru logger instance.\n    \"\"\"\n\n    self.remove_handler()\n\n    self._check_env()\n    self._check_config()\n\n    if self.config.stream.std_handler.enabled:\n        self._add_stream_std_handler()\n\n    if self.config.file.log_handlers.enabled:\n        self._add_file_log_handler()\n        self._add_file_err_handler()\n\n    if self.config.file.json_handlers.enabled:\n        self._add_file_json_handler()\n        self._add_file_json_err_handler()\n\n    self._load_intercept_handlers()\n\n    return logger\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"api-docs/LoggerLoader/#src.beans_logging.LoggerLoader.remove_handler","title":"<code>remove_handler(handler=None, handler_type='NAME')</code>","text":"<p>Remove all handlers or specific handler by name or id from logger.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>The <code>handler_type</code> argument value '{handler_type}' is invalid, must be 'NAME' or 'ID'!</p> <p>Parameters:</p> Name Type Description Default <code>handler</code> <code>str</code> <p>Handler name or id to remove. Defaults to None.</p> <code>None</code> <code>handler_type</code> <code>int</code> <p>Handler type to remove, must be 'NAME' or 'ID'. Defaults to 'name'.</p> <code>'NAME'</code> Source code in <code>src/beans_logging/_base.py</code> <pre><code>@validate_call\ndef remove_handler(self, handler: str | None = None, handler_type: str = \"NAME\"):\n    \"\"\"Remove all handlers or specific handler by name or id from logger.\n\n    Raises:\n        ValueError: The `handler_type` argument value '{handler_type}' is invalid, must be 'NAME' or 'ID'!\n\n    Args:\n        handler      (str, optional): Handler name or id to remove. Defaults to None.\n        handler_type (int, optional): Handler type to remove, must be 'NAME' or 'ID'. Defaults to 'name'.\n    \"\"\"\n\n    if handler:\n        handler_type = handler_type.strip().upper()\n        if handler_type == \"NAME\":\n            if handler in self.handlers_map:\n                _handler_id = self.handlers_map[handler]\n                logger.remove(_handler_id)\n                self.handlers_map.pop(handler)\n                return\n        elif handler_type == \"ID\":\n            if handler in self.handlers_map.values():\n                logger.remove(handler)\n                for _handler_name, _handler_id in self.handlers_map.items():\n                    if handler == _handler_id:\n                        self.handlers_map.pop(_handler_name)\n                return\n        else:\n            raise ValueError(\n                f\"`handler_type` argument value '{handler_type}' is invalid, must be 'NAME' or 'ID'!\"\n            )\n\n    logger.remove()\n    self.handlers_map.clear()\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"api-docs/LoggerLoader/#src.beans_logging.LoggerLoader.update_config","title":"<code>update_config(config)</code>","text":"<p>Update logger config with new config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>(Union[LoggerConfigPM, dict], required)</code> <p>New logger config to update loaded config.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>Failed to load <code>config</code> argument into . Source code in <code>src/beans_logging/_base.py</code> <pre><code>@validate_call\ndef update_config(self, config: LoggerConfigPM | dict[str, Any]):\n    \"\"\"Update logger config with new config.\n\n    Args:\n        config (Union[LoggerConfigPM, dict], required): New logger config to update loaded config.\n\n    Raises:\n        Exception: Failed to load `config` argument into &lt;class 'LoggerConfigPM'&gt;.\n    \"\"\"\n\n    if isinstance(config, dict):\n        if \"2.0.0\" &lt;= pydantic.__version__:\n            _config_dict = self.config.model_dump()\n        else:\n            _config_dict = self.config.dict()\n\n        _merged_dict = deep_merge(_config_dict, config)\n        try:\n            self.config = LoggerConfigPM(**_merged_dict)\n        except Exception:\n            logger.critical(\n                \"Failed to load `config` argument into &lt;class 'LoggerConfigPM'&gt;.\"\n            )\n            raise\n\n    elif isinstance(config, LoggerConfigPM):\n        self.config = config\n</code></pre>","tags":["api-docs","api-reference"]},{"location":"dev/build/","title":"\ud83c\udfd7\ufe0f Build Python Package","text":"<p>To build the python package, run the following command:</p> <pre><code># Install python build dependencies:\npip install -r ./requirements/requirements.build.txt\n\n# Build python package:\npython -m build\n# Or use the build script:\n./scripts/build.sh\n</code></pre>","tags":["dev","development"]},{"location":"dev/build/#build","title":"Build","text":"<pre><code># Install python build:\npip install -U build\n\n# Build help:\npython -m build --help\n</code></pre>","tags":["dev","development"]},{"location":"dev/build/#references","title":"References","text":"<ul> <li>Python Packaging User Guide</li> <li>Packaging Python Projects</li> <li>Writing your <code>pyproject.toml</code></li> <li>Setuptools Documentation</li> <li>Blogs:<ul> <li>Python Packaging Best Practices</li> <li>Generic Folder Structure for your Machine Learning Projects</li> <li>How to Upload your Python Package to PyPI</li> </ul> </li> </ul>","tags":["dev","development"]},{"location":"dev/contributing/","title":"\ud83e\udd1d Contributing","text":"<p>This project is encourages contributions!</p>","tags":["dev","development"]},{"location":"dev/diagrams/","title":"\ud83d\uddbc\ufe0f Diagrams","text":"<p>This page contains diagrams that illustrate the architecture of the module.</p>","tags":["dev","development"]},{"location":"dev/diagrams/#class","title":"Class","text":"","tags":["dev","development"]},{"location":"dev/diagrams/#package","title":"Package","text":"","tags":["dev","development"]},{"location":"dev/docs/","title":"\ud83d\udcdd Docs","text":"<p>To build the documentation, run the following command:</p> <pre><code># Install python documentation dependencies:\npip install -r ./requirements/requirements.docs.txt\n\n# Serve documentation locally (for development):\nmkdocs serve\n# Or use the docs script:\n./scripts/docs.sh\n\n# Or build documentation:\nmkdocs build\n# Or use the docs script:\n./scripts/docs.sh -b\n</code></pre>","tags":["dev","development"]},{"location":"dev/docs/#diagrams","title":"Diagrams","text":"<p>Prerequisites:</p> <ul> <li>Install Graphviz</li> </ul> <p>To generate diagrams, run the following command:</p> <pre><code># Install python documentation dependencies:\npip install -r ./requirements/requirements.docs.txt\n\n# Generate diagrams:\n./scripts/diagrams.sh\n</code></pre>","tags":["dev","development"]},{"location":"dev/docs/#mkdocs-material","title":"MkDocs Material","text":"","tags":["dev","development"]},{"location":"dev/docs/#installation","title":"Installation","text":"<pre><code># Install mkdocs-material and mkdocstrings:\npip install -U mkdocs-material mkdocstrings[python]\n</code></pre>","tags":["dev","development"]},{"location":"dev/docs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>","tags":["dev","development"]},{"location":"dev/docs/#docs-layout","title":"Docs layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>","tags":["dev","development"]},{"location":"dev/docs/#references","title":"References","text":"<ul> <li>MkDocs Documentation</li> <li>MkDocs Material Documentation</li> <li>mkdocstrings Documentation</li> </ul>","tags":["dev","development"]},{"location":"dev/file-structure/","title":"\ud83d\udcc2 File Structure","text":"<pre><code>project/\n\u251c\u2500\u2500 .github/                # GitHub specific files\n|   \u251c\u2500\u2500 workflows/              # GitHub actions as workflows\n|   \u2514\u2500\u2500 release.yml             # Categories and labels for release notes\n\u251c\u2500\u2500 .vscode/                # VSCode specific files\n|   \u251c\u2500\u2500 extensions.json         # Recommended extensions for the workspace\n|   \u2514\u2500\u2500 settings.json           # Common VSCode settings for the workspace (e.g. formatting, linting, etc...)\n\u251c\u2500\u2500 build/                  # Build files and directories (SHOULD NOT BE COMMITTED TO REPOSITORY)\n\u251c\u2500\u2500 dist/                   # Built distributions of this project (SHOULD NOT BE COMMITTED TO REPOSITORY)\n\u251c\u2500\u2500 docs/                   # Documentation of this project\n|   \u251c\u2500\u2500 assets/                 # Any assets (images, audios, videos, js, css, html, etc...) used for the documentation\n|   \u251c\u2500\u2500 diagrams/               # Diagrams related to this project\n|   \u251c\u2500\u2500 blog/                   # Blog posts related to this project\n|   \u2514\u2500\u2500 .../                    # MkDocs pages - markdown files\n\u251c\u2500\u2500 examples/               # Example source codes of this project\n\u251c\u2500\u2500 requirements/           # Python dependency requirements for different environments\n\u251c\u2500\u2500 scripts/                # Helpful scripts to automate tasks or assist in the development process\n\u251c\u2500\u2500 site/                   # Built static site of the documentation (SHOULD NOT BE COMMITTED TO REPOSITORY)\n\u251c\u2500\u2500 src/                    # Source codes of this project\n|   \u251c\u2500\u2500 modules/                # External modules for this project\n|   |   \u251c\u2500\u2500 module_1/\n|   |   \u251c\u2500\u2500 module_2/\n|   |   \u2514\u2500\u2500 .../\n|   \u2514\u2500\u2500 beans_logging/            # Main CODEBASE of this project as a python module\n|       \u251c\u2500\u2500 __init__.py             # Initialize the module to be used as a package\n|       \u251c\u2500\u2500 __version__.py          # Version of the module (should be updated and used with each release)\n|       \u2514\u2500\u2500 ...                     # Other main python files of this module\n\u251c\u2500\u2500 templates/              # Template files (if any, e.g. config files, etc...) used in this project\n\u251c\u2500\u2500 tests/                  # Tests for this project\n|   \u251c\u2500\u2500 __init__.py             # Initialize the test module\n|   \u251c\u2500\u2500 conftest.py             # Presets for pytest (e.g. fixtures, plugins, pre/post test hooks, etc...)\n|   \u251c\u2500\u2500 test_1.py               # Test case files\n|   \u251c\u2500\u2500 test_2.py\n|   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 __init__.py             # Initialize the whole project as a python module to import from other modules\n\u251c\u2500\u2500 .editorconfig           # Editor configuration for consistent coding styles for different editors\n\u251c\u2500\u2500 .env                    # Environment variables file (SHOULD NOT BE COMMITTED TO REPOSITORY)\n\u251c\u2500\u2500 .env.example            # Example environment variables file\n\u251c\u2500\u2500 .gitignore              # Files and directories to be ignored by git (e.g. data, models, results, etc...)\n\u251c\u2500\u2500 .markdownlint.json      # Markdown linting rules\n\u251c\u2500\u2500 .pre-commit-config.yaml # Pre-commit configuration file\n\u251c\u2500\u2500 CHANGELOG.md            # List of changes for each version of the project\n\u251c\u2500\u2500 environment.yml         # Conda environment file\n\u251c\u2500\u2500 LICENSE.txt             # License file for this project\n\u251c\u2500\u2500 Makefile                # Makefile for common commands and automation\n\u251c\u2500\u2500 MANIFEST.in             # Manifest file for setuptools (to include/exclude files in the source distribution)\n\u251c\u2500\u2500 mkdocs.yml              # MkDocs configuration file\n\u251c\u2500\u2500 pyproject.toml          # PEP 518 configuration file for python packaging\n\u251c\u2500\u2500 pytest.ini              # Pytest configuration file\n\u251c\u2500\u2500 README.md               # Main README file for this project\n\u251c\u2500\u2500 requirements.txt        # Main python dependency requirements for this project\n\u251c\u2500\u2500 setup.cfg               # Configuration for setuptools\n\u2514\u2500\u2500 setup.py                # Setup script for setuptools (for backward compatibility)\n</code></pre>","tags":["dev","development"]},{"location":"dev/related-projects/","title":"\ud83d\uddc2 Related Projects","text":"<p>This section lists related projects or sub-module projects that are part of this project.</p>","tags":["dev","development"]},{"location":"dev/roadmap/","title":"\ud83d\udee4 Roadmap","text":"<p>This project is still in its early stages of development.</p> <p>The following is a list of features that are planned for future releases:</p>","tags":["dev","development"]},{"location":"dev/sitemap/","title":"\ud83d\uddfa\ufe0f Sitemap","text":"<ul> <li>Home</li> <li>Getting Started<ul> <li>Prerequisites</li> <li>Installation</li> <li>Configuration</li> <li>Examples</li> </ul> </li> <li>API Documentation<ul> <li>LoggerLoader</li> </ul> </li> <li>Development<ul> <li>Test</li> <li>Build</li> <li>Docs</li> <li>Scripts<ul> <li>clean.sh</li> <li>get-version.sh</li> <li>test.sh</li> <li>bump-version.sh</li> <li>build.sh</li> <li>release.sh</li> <li>changelog.sh</li> <li>diagrams.sh</li> <li>docs.sh</li> </ul> </li> <li>CI/CD<ul> <li>1.bump-version.yml</li> <li>2.build-publish.yml</li> <li>3.update-changelog.yml</li> <li>publish-docs.yml</li> </ul> </li> <li>Diagrams</li> <li>File Structure</li> <li>Sitemap</li> <li>Related Projects</li> <li>Contributing</li> <li>Roadmap</li> </ul> </li> <li>Release Notes</li> <li>About<ul> <li>FAQ</li> <li>Authors</li> <li>Contact</li> <li>License</li> </ul> </li> </ul>","tags":["dev","development"]},{"location":"dev/test/","title":"\ud83e\uddea Test","text":"<p>To run tests, run the following command:</p> <pre><code># Install python test dependencies:\npip install .[test]\n\n# Run tests:\npython -m pytest -sv -o log_cli=true\n# Or use the test script:\n./scripts/test.sh -l -v -c\n</code></pre>","tags":["dev","development"]},{"location":"dev/test/#pytest","title":"Pytest","text":"<pre><code># Install pytest:\npip install -U pytest pytest-cov pytest-xdist pytest-benchmark\n\n# Run tests:\npython -m pytest\n\n# Pytest help:\npython -m pytest --help\n</code></pre>","tags":["dev","development"]},{"location":"dev/test/#references","title":"References","text":"<ul> <li>Pytest Documentation</li> <li>Pytest Getting Started</li> <li>Pytest Fixtures</li> <li>Blogs:<ul> <li>https://docs.pytest.org/en/latest/goodpractices.html</li> <li>https://emimartin.me/pytest_best_practices</li> <li>https://esaezgil.com/post/unittesting_pitfalls</li> <li>https://pytest-with-eric.com/mocking/pytest-common-mocking-problems</li> </ul> </li> </ul>","tags":["dev","development"]},{"location":"dev/cicd/","title":"\ud83d\udc77 CI/CD","text":"<p>This section provides information on how to setup and configure CI/CD pipelines for this project.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/#github-actions","title":"GitHub Actions","text":"<ul> <li><code>1.bump-version.yml</code>: Bumps the project version.</li> <li><code>2.build-publish.yml</code>: Builds, publishes and creates release of python package.</li> <li><code>3.update-changelog.yml</code>: Updates the changelog.</li> <li><code>publish-docs.yml</code>: Publishes the documentation.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/#references","title":"References","text":"<ul> <li>GitHub Actions Documentation</li> <li>GitHub Actions Marketplace</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/","title":"\u2b06\ufe0f Bump Version","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#overview","title":"Overview","text":"<p>This GitHub Action automates the process of bumping the project version. It allows users to choose whether to increment the version as a patch, minor, or major release. This workflow consists of two main jobs:</p> <ol> <li>Test: Runs tests before bumping the version.</li> <li>Bump Version: Increases the project version and commits the changes.</li> </ol>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#how-it-works","title":"How It Works","text":"<p>The workflow is triggered manually via GitHub's <code>workflow_dispatch</code> event. Users must select the type of version bump before execution.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#workflow-configuration","title":"Workflow Configuration","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#trigger","title":"Trigger","text":"<p>The action is triggered manually by dispatching a workflow with an input parameter <code>bump_type</code>, which can have one of the following values:</p> <ul> <li><code>patch</code></li> <li><code>minor</code></li> <li><code>major</code></li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#jobs","title":"Jobs","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#1-test-11-test","title":"1. Test (1.1. Test)","text":"<p>This job ensures the code is tested before making version changes.</p> <ul> <li>Runs on: <code>ubuntu-24.04</code></li> <li>Permissions: <code>contents: read</code></li> <li>Steps:<ol> <li>Checkout the repository</li> <li>Install dependencies (from <code>requirements/requirements.test.txt</code>)</li> <li>Run tests using <code>pytest</code> via <code>./scripts/test.sh -l</code></li> </ol> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#2-bump-version-12-bump-version","title":"2. Bump Version (1.2. Bump Version)","text":"<p>This job updates the project version after tests pass.</p> <ul> <li>Runs on: <code>ubuntu-24.04</code></li> <li>Permissions: <code>contents: write</code></li> <li>Steps:<ol> <li>Checkout the repository (with full history)</li> <li>Bump the version using <code>./scripts/bump-version.sh</code></li> <li>Commits and pushes changes using GitHub Actions bot</li> </ol> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#usage","title":"Usage","text":"<p>To manually trigger this workflow:</p> <ol> <li>Navigate to the repository on GitHub.</li> <li>Go to the Actions tab.</li> <li>Select \"1. Bump Version\" from the list.</li> <li>Click \"Run workflow\".</li> <li>Choose a version bump type (<code>patch</code>, <code>minor</code>, or <code>major</code>).</li> <li>Click \"Run workflow\" to start the process.</li> </ol>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#environment-variables","title":"Environment Variables","text":"<p>The workflow uses the following environment variables:</p> <ul> <li><code>GITHUB_TOKEN</code>: GitHub-provided authentication token for making commits.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#scripts-used","title":"Scripts Used","text":"<ul> <li><code>test.sh</code>: Runs the test suite.</li> <li><code>bump-version.sh</code>: Handles version incrementing.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#notes","title":"Notes","text":"<ul> <li>Ensure that <code>bump-version.sh</code> supports <code>-b</code>, <code>-c</code>, and <code>-p</code> options.</li> <li>The workflow ensures that version bumping occurs only if tests pass.</li> <li>The changes are committed and pushed automatically to the repository.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/1.bump-version/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the workflow fails in the <code>test</code> step, check test logs for errors.</li> <li>If version bumping fails, ensure <code>bump-version.sh</code> is executable and correctly configured.</li> <li>If permissions errors occur, verify that GitHub Actions has the required <code>contents: write</code> permission.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/","title":"\ud83d\ude80 Build and Publish","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#overview","title":"Overview","text":"<p>This GitHub Action automates the process of building and publishing the project. It triggers automatically after a version bump or when a tag (<code>v*.*.*</code>) is pushed. The workflow builds the package and optionally publishes it to a package registry.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#how-it-works","title":"How It Works","text":"<p>The workflow runs in the following scenarios:</p> <ul> <li>After Bump Version workflow completes.</li> <li>When a new tag (<code>v*.*.*</code>) is pushed to the repository.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#workflow-configuration","title":"Workflow Configuration","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#trigger","title":"Trigger","text":"<ul> <li>Triggered by:<ul> <li>Completion of <code>1. Bump Version</code> workflow.</li> <li>Push event on tags matching <code>v*.*.*</code>.</li> </ul> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#jobs","title":"Jobs","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#1-build-and-publish","title":"1. Build and Publish","text":"<p>This job builds the package and creates a release.</p> <ul> <li>Runs on: <code>ubuntu-24.04</code></li> <li>Permissions: <code>contents: write</code></li> <li>Steps:<ol> <li>Checkout the repository</li> <li>Install dependencies (from <code>requirements/requirements.build.txt</code>)</li> <li>Build the package using <code>./scripts/build.sh -c</code></li> <li>Create a release using GitHub CLI (<code>gh release create</code>)</li> </ol> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#usage","title":"Usage","text":"<p>This workflow runs automatically when a new version is tagged. However, you can manually trigger a tag and push it:</p> <ol> <li>Bump the version using the <code>1. Bump Version</code> workflow.</li> <li> <p>Create a tag manually and push it:</p> <pre><code>git tag v1.2.3\ngit push origin v1.2.3\n</code></pre> </li> <li> <p>The workflow will build and publish the package.</p> </li> </ol>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>GITHUB_TOKEN</code>: Used for creating GitHub releases.</li> <li><code>PYPI_API_TOKEN</code> (if enabled): Used for publishing packages to PyPI.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#scripts-used","title":"Scripts Used","text":"<ul> <li><code>build.sh</code>: Builds the package.</li> <li><code>get-version.sh</code>: Retrieves the current version.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#notes","title":"Notes","text":"<ul> <li>This workflow supports both GitHub Releases and optional package publishing.</li> <li>Ensure <code>build.sh</code> is executable and correctly configured.</li> <li>If the workflow fails, check logs for errors related to dependencies or authentication.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/2.build-publish/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the build step fails, ensure dependencies are correctly installed.</li> <li>If release creation fails, verify that <code>GITHUB_TOKEN</code> has the necessary permissions.</li> <li>If publishing to PyPI fails, check that the API token is correctly set up in repository secrets.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/","title":"\ud83d\udca5 Update Changelog","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#overview","title":"Overview","text":"<p>This GitHub Action automates the process of updating the changelog after a new release is built and published. It ensures that the changelog remains up to date with the latest changes in the repository.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#how-it-works","title":"How It Works","text":"<p>The workflow is triggered automatically after the Build and Publish workflow is successfully completed.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#workflow-configuration","title":"Workflow Configuration","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#trigger","title":"Trigger","text":"<ul> <li>Triggered by:<ul> <li>Completion of <code>2. Build and Publish</code> workflow.</li> </ul> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#jobs","title":"Jobs","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#1-update-changelog","title":"1. Update Changelog","text":"<p>This job updates the changelog after a new release.</p> <ul> <li>Runs on: <code>ubuntu-24.04</code></li> <li>Permissions: <code>contents: write</code></li> <li>Steps:<ol> <li>Checkout the repository (with full history for changelog updates)</li> <li>Update the changelog using <code>./scripts/changelog.sh -c -p</code></li> <li>Commits and pushes changes using GitHub Actions bot</li> </ol> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#usage","title":"Usage","text":"<p>This workflow runs automatically when a new release is created. However, you can manually update the changelog by running the script locally:</p> <pre><code>./scripts/changelog.sh -c -p\n</code></pre>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>GITHUB_TOKEN</code>: Used for authentication and committing changes.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#scripts-used","title":"Scripts Used","text":"<ul> <li><code>changelog.sh</code>: Updates the changelog file.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#notes","title":"Notes","text":"<ul> <li>Ensure that <code>changelog.sh</code> is executable and correctly configured.</li> <li>The workflow ensures that changelog updates occur only after a successful release build.</li> <li>The changes are committed and pushed automatically to the repository.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/3.update-changelog/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the workflow fails, ensure that <code>changelog.sh</code> is present and executable.</li> <li>If there are permissions errors, verify that GitHub Actions has the required <code>contents: write</code> permission.</li> <li>Check logs for any issues related to Git authentication or script execution.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/","title":"\ud83d\udcdd Publish Docs","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#overview","title":"Overview","text":"<p>This GitHub Action automates the process of publishing documentation using MkDocs whenever changes are pushed to the <code>main</code> branch. It ensures that the latest documentation is deployed automatically.</p>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#how-it-works","title":"How It Works","text":"<p>The workflow is triggered when changes are made to:</p> <ul> <li>The <code>docs/</code> directory.</li> <li>The <code>mkdocs.yml</code> configuration file.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#workflow-configuration","title":"Workflow Configuration","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#trigger","title":"Trigger","text":"<ul> <li>Triggered by:<ul> <li>A push event to the <code>main</code> branch that modifies documentation files.</li> </ul> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#jobs","title":"Jobs","text":"","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#1-publish-docs","title":"1. Publish Docs","text":"<p>This job builds and deploys the documentation using MkDocs.</p> <ul> <li>Runs on: <code>ubuntu-24.04</code></li> <li>Permissions: <code>contents: write</code></li> <li>Steps:<ol> <li>Checkout the repository (with full history for proper deployment tracking).</li> <li>Install dependencies from <code>requirements/requirements.docs.txt</code></li> <li>Publish the documentation using <code>mkdocs gh-deploy --force</code></li> </ol> </li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#usage","title":"Usage","text":"<p>This workflow runs automatically when changes are pushed to the <code>main</code> branch. However, you can manually deploy the documentation by running the following command locally:</p> <pre><code>mkdocs gh-deploy --force\n</code></pre>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>GITHUB_TOKEN</code>: Used for authentication and deploying the documentation.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#scripts-used","title":"Scripts Used","text":"<ul> <li><code>mkdocs.yml</code>: Configuration file for MkDocs.</li> <li>Files in <code>docs/</code>: Documentation content.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#notes","title":"Notes","text":"<ul> <li>Ensure that <code>mkdocs</code> and required dependencies are correctly installed in <code>requirements.docs.txt</code>.</li> <li>The workflow ensures that documentation updates occur only when relevant files are modified.</li> <li>The changes are committed and published automatically to GitHub Pages.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/cicd/publish-docs/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the workflow fails, ensure that <code>mkdocs</code> is properly installed and configured.</li> <li>If deployment issues occur, verify that GitHub Actions has the required <code>contents: write</code> permission.</li> <li>Check logs for any issues related to Git authentication or MkDocs execution.</li> </ul>","tags":["dev","development","cicd"]},{"location":"dev/scripts/","title":"\ud83d\udd28 Scripts","text":"<p>This document provides an overview and usage instructions for the following scripts in this project:</p> <ul> <li><code>clean.sh</code></li> <li><code>get-version.sh</code></li> <li><code>test.sh</code></li> <li><code>bump-version.sh</code></li> <li><code>build.sh</code></li> <li><code>release.sh</code></li> <li><code>changelog.sh</code></li> <li><code>diagrams.sh</code></li> <li><code>docs.sh</code></li> </ul> <p>All the scripts are located in the <code>scripts</code> directory:</p> <pre><code>scripts/\n\u251c\u2500\u2500 build.sh\n\u251c\u2500\u2500 bump-version.sh\n\u251c\u2500\u2500 changelog.sh\n\u251c\u2500\u2500 clean.sh\n\u251c\u2500\u2500 diagrams.sh\n\u251c\u2500\u2500 docs.sh\n\u251c\u2500\u2500 get-version.sh\n\u251c\u2500\u2500 release.sh\n\u2514\u2500\u2500 test.sh\n</code></pre> <p>These scripts are designed to be used in a Linux or macOS environment. They may work in a Windows environment with the appropriate tools installed, but this is not guaranteed.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/build.sh/","title":"\ud83c\udfd7\ufe0f build.sh","text":"<p>This script is used to build a Python project and optionally run tests and publish the package. It also includes a cleaning operation to clear the build directories.</p> <p>This script has the following key features:</p> <ul> <li>Checking for required tools: It verifies if Python and the build package are installed on the system. If tests are not disabled, it also checks if pytest is installed. If uploading is enabled, it checks for the presence of Twine.</li> <li>Command-line argument parsing: It parses <code>-c</code> or <code>--disable-clean</code> to disable cleaning the build directories, <code>-t</code> or <code>--test</code> to enable running tests, <code>-u</code> or <code>--upload</code> to enable publishing the package, and <code>-p</code> or <code>--production</code> to switch the package repository from staging (default) to production.</li> <li>Clean operation: Cleans the build directories before and after building (if enabled). If <code>-c</code> or <code>--disable-clean</code> is passed, the script will not clean the build directories.</li> <li>Testing operation: Runs pytest tests if enabled by <code>-t</code> or <code>--test</code> flag.</li> <li>Build operation: Builds a Python package using the Python build package.</li> <li>Publishing operation: Publishes the built package to a PyPi repository using Twine if the <code>-u</code> or <code>--upload</code> flag is passed. Defaults to the TestPyPi (staging) repository, but can be switched to the production (PyPi) repository using the <code>-p</code> or <code>--production</code> flag.</li> </ul> <p>Usage:</p> <p>To execute the build script with the different flags, use the following commands:</p> <pre><code>./build.sh [-c|--disable-clean] [-t|--test] [-u|--upload] [-p|--production]\n</code></pre> <p>Examples:</p> <ul> <li>To build without cleaning: <code>./build.sh -c</code></li> <li>To build with running tests: <code>./build.sh -t</code></li> <li>To build and publish to the staging repository: <code>./build.sh -u</code></li> <li>To build and publish to the production repository: <code>./build.sh -u -p</code></li> </ul> <p>This script is particularly beneficial for developers, streamlining the build, testing, and publishing process. It provides a one-stop solution for all the build needs of a Python project, reducing chances of errors and ensuring consistency.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/bump-version.sh/","title":"\ud83c\udff7 bump-version.sh","text":"<p>This script is used to manage the versioning of the project. It allows you to increment the major, minor, or patch part of the version, as per Semantic Versioning rules.</p> <p>The script carries out the following operations:</p> <ul> <li>Loading environment variables: If a <code>.env</code> file is present in the root directory, the script loads the environment variables from this file.</li> <li>Sets variables: Sets the <code>VERSION_FILE_PATH</code> and other variables. The <code>VERSION_FILE_PATH</code> variable is either loaded from the environment or defaults to <code>src/beans_logging/__version__.py</code>.</li> <li>Parses input arguments: It parses the <code>-b</code> or <code>--bump-type</code> argument for the type of version bump (<code>major</code>, <code>minor</code>, or <code>patch</code>) and <code>-p</code> or <code>--push-tag</code> to decide whether to push the tag to the Git repository or not.</li> <li>Checks and increments the version: It uses <code>get-version.sh</code> to extract the current version from the file specified by <code>VERSION_FILE_PATH</code>. Based on the bump type, it increments the appropriate part of the version and writes the new version back to the file.</li> <li>Commits and tags: If the <code>-p</code> or <code>--push-tag</code> flag was provided, it adds and commits the changes, pushes the changes, creates a new tag with the new version, and pushes the tag to the Git repository. It will prevent the operation if the tag already exists.</li> </ul> <p>Usage:</p> <p>To execute the bump version script, run the following command in the terminal:</p> <pre><code>./bump-version.sh -b=&lt;bump_type&gt; -p\n</code></pre> <p>Replace <code>&lt;bump_type&gt;</code> with either <code>major</code>, <code>minor</code>, or <code>patch</code> to indicate which part of the version to increment. The <code>-p</code> or <code>--push-tag</code> flag tells the script to commit the changes and push the tag to the Git repository.</p> <p>Examples:</p> <p>To bump the <code>minor</code> version and push the new tag, run:</p> <pre><code>./bump-version.sh -b=minor -p\n</code></pre> <p>This script streamlines the versioning process, reducing the chances of errors and ensuring consistency in versioning.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/bump-version.sh/#references","title":"References","text":"<ul> <li>https://semver.org</li> </ul>","tags":["dev","development","scripts"]},{"location":"dev/scripts/changelog.sh/","title":"\ud83d\udccc changelog.sh","text":"<p>This script automates updating both a <code>CHANGELOG.md</code> file and a <code>docs/release-notes.md</code> file using release information fetched from GitHub. It ensures consistent release documentation across the project and optionally commits and pushes changes to the Git repository.</p> <p>The script performs the following operations:</p> <ul> <li>Environment setup:  <ul> <li>Runs from the project root.  </li> <li>Loads environment variables from a <code>.env</code> file if present.  </li> </ul> </li> <li>Dependency checks:  <ul> <li>Ensures the GitHub CLI (<code>gh</code>) is installed and authenticated.  </li> <li>If <code>--commit</code> is specified, verifies that <code>git</code> is available.  </li> </ul> </li> <li>Variables setup:  <ul> <li><code>CHANGELOG_FILE_PATH</code> \u2192 Path to the changelog file (default: <code>./CHANGELOG.md</code>).  </li> <li><code>RELEASE_NOTES_FILE_PATH</code> \u2192 Path to the release notes file (default: <code>./docs/release-notes.md</code>).  </li> </ul> </li> <li>Input parsing:  <ul> <li><code>-c</code> or <code>--commit</code>: Commit changelog and release notes updates.  </li> <li><code>-p</code> or <code>--push</code>: Push updates to the remote repository (requires <code>-c</code>).  </li> </ul> </li> <li>Changelog update:  <ul> <li>Fetches the latest release tag and body from GitHub (<code>gh release view</code>).  </li> <li>Updates <code>CHANGELOG.md</code> with a new section for the latest release, including date and notes.  </li> </ul> </li> <li>Release notes update:  <ul> <li>Updates <code>docs/release-notes.md</code> with a formatted entry for the latest release.  </li> <li>Adds a YAML front matter block and header if the file does not already exist.  </li> </ul> </li> <li>Commit and push (optional):  <ul> <li>If <code>-c</code> is provided, stages and commits both updated files with a commit message.  </li> <li>If <code>-p</code> is also provided, pushes the commit to the remote repository.</li> </ul> </li> </ul>","tags":["dev","development","scripts"]},{"location":"dev/scripts/changelog.sh/#usage","title":"Usage","text":"<p>To execute <code>changelog.sh</code>, run:</p> <pre><code>./changelog.sh [-c|--commit] [-p|--push]\n</code></pre>","tags":["dev","development","scripts"]},{"location":"dev/scripts/clean.sh/","title":"\ud83e\uddf9 clean.sh","text":"<p>This script is designed to clean up the build environment by removing artifacts and other temporary or unwanted files and directories.</p> <p>The script performs the following operations:</p> <ul> <li>Delete system files: Finds and deletes all <code>.DS_Store</code> and <code>.Thumbs.db</code> files in the project directory and its subdirectories.</li> <li>Delete cache directories: Finds and deletes all <code>__pycache__</code> directories in the project directory and its subdirectories.</li> <li>Delete project-related directories: Removes directories created during the test and build process or by tools used in the project, such as <code>.benchmarks</code>, <code>.pytest_cache</code>, <code>build</code>, and <code>dist</code> directories.</li> <li>Delete <code>.coverage</code> file: Removes the <code>.coverage</code> file that's created when coverage information is collected for the project.</li> </ul> <p>Usage:</p> <p>To execute the clean script, simply run the following command in the terminal:</p> <pre><code>./clean.sh [-a|--all]\n</code></pre> <p>Examples:</p> <ul> <li>To clean just non-essential files: <code>./clean.sh</code></li> <li>To clean all files: <code>./clean.sh -a</code></li> </ul> <p>This will clean up the project directory, removing any unnecessary files and directories and ensuring a clean environment for a fresh build.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/diagrams.sh/","title":"\ud83d\uddbc\ufe0f diagrams.sh","text":"<p>This script generates UML diagrams for a specified Python module using <code>pyreverse</code>. It checks for dependencies, loads environment variables, sets directories, and processes command-line arguments for customization of module names, directories, and output locations.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/diagrams.sh/#overview","title":"Overview","text":"<p>The script performs the following operations:</p> <ul> <li> <p>Dependency Checks: Verifies the presence of required tools:</p> <ul> <li><code>graphviz</code> for <code>.dot</code> file handling.</li> <li><code>python</code> for running Python-based commands.</li> <li><code>pylint</code> (with <code>pyreverse</code>) for generating UML diagrams.</li> </ul> </li> <li> <p>Environment Variable Setup: Sets default values for module name, module directory, and output directory (<code>MODULE_NAME</code>, <code>MODULE_DIR</code>, <code>OUTPUT_DIR</code>). These can be customized via environment variables or command-line arguments.</p> </li> <li> <p>Argument Parsing: Parses optional arguments to allow customization:</p> <ul> <li><code>-m</code> or <code>--module-name</code> to specify the module name.</li> <li><code>-d</code> or <code>--module-dir</code> to specify the module directory.</li> <li><code>-o</code> or <code>--output-dir</code> to specify the output directory.</li> </ul> </li> <li> <p>Directory Creation: Creates subdirectories within the output directory for organizing different types of UML and flowchart outputs:</p> <ul> <li><code>classes</code> for class diagrams.</li> <li><code>packages</code> for package diagrams.</li> </ul> </li> <li> <p>Diagram Generation: Runs <code>pyreverse</code> to create UML diagrams in multiple formats (<code>html</code>, <code>pdf</code>, <code>png</code>, and <code>svg</code>) and organizes them into respective directories.</p> </li> <li> <p>Completion Message: Displays a message confirming successful generation of diagrams.</p> </li> </ul>","tags":["dev","development","scripts"]},{"location":"dev/scripts/diagrams.sh/#usage","title":"Usage","text":"<p>To run the script:</p> <pre><code>./diagrams.sh -m=&lt;module_name&gt; -d=&lt;module_dir&gt; -o=&lt;output_dir&gt;\n</code></pre>","tags":["dev","development","scripts"]},{"location":"dev/scripts/docs.sh/","title":"\ud83d\udcdd docs.sh","text":"<p>This script is used to manage the documentation for the project, providing options to either serve a local documentation server or build the documentation as static HTML files.</p> <p>The script performs the following operations:</p> <ul> <li>Serving documentation: If no flags are set, runs <code>mkdocs serve</code> to start a local documentation server for live preview.</li> <li>Building documentation: If the <code>-b</code> or <code>--build</code> flag is set, the script builds the documentation as static HTML files using <code>mkdocs build</code>, placing the output in the <code>site</code> directory.</li> <li>Publishing documentation: If the <code>-p</code> or <code>--publish</code> flag is set, the script can be extended to publish the documentation to GitHub Pages.</li> </ul> <p>Usage:</p> <p>To execute the documentation script, use the following command in the terminal:</p> <pre><code>./docs.sh [-b|--build] [-p|--publish]\n</code></pre> <p>Examples:</p> <ul> <li>To serve the documentation: <code>./docs.sh</code></li> <li>To build the documentation: <code>./docs.sh -b</code></li> <li>To publish the documentation: <code>./docs.sh -p</code></li> </ul>","tags":["dev","development","scripts"]},{"location":"dev/scripts/get-version.sh/","title":"\ud83d\udd0d get-version.sh","text":"<p>This script is used to retrieve the current version of the application from a specified version file.</p> <p>The script performs the following operations:</p> <ul> <li><code>VERSION_FILE_PATH</code> is either loaded from the environment or, if it's not present in the environment, it defaults to <code>src/beans_logging/__version__.py</code>.</li> <li>It first checks if the <code>VERSION_FILE_PATH</code> variable is not empty and if the file exists. If these conditions are met, it retrieves the value of <code>__version__</code> from the file by using <code>grep</code>, <code>awk</code>, and <code>tr</code> commands. The <code>grep</code> command filters the line containing <code>__version__ =</code> , the <code>awk</code> command splits the line into two parts at <code>=</code>, and the <code>tr</code> command removes the quotes around the version. If these operations fail, it exits the script with status code <code>2</code>.</li> <li>If the <code>VERSION_FILE_PATH</code> variable is empty or the file does not exist, it sets the current version to <code>0.0.0</code>.</li> <li>Finally, it echoes the current version to the console.</li> </ul> <p>Usage:</p> <p>To execute the get version script, simply run the following command in the terminal:</p> <pre><code>./get-version.sh\n</code></pre> <p>This script can be used to conveniently fetch the version. It is used by the <code>bump-version.sh</code> script to retrieve the current version before incrementing it.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/release.sh/","title":"\ud83d\ude80 release.sh","text":"<p>This script automates the creation of GitHub Releases for the project. It optionally performs a build, retrieves the current version, and uploads artifacts from the <code>dist</code> directory to a new GitHub Release with autogenerated notes.</p> <p>The script performs the following operations:</p> <ul> <li>Environment setup:   Ensures it runs from the project root and sources environment variables from <code>.env</code> if available.</li> <li>Dependency checks:   Verifies that <code>git</code> and <code>gh</code> (GitHub CLI) are installed, and that the user is authenticated with <code>gh auth login</code>.</li> <li>Optional build:   If the <code>-b</code> or <code>--build</code> flag is set, runs <code>./scripts/build.sh -c</code> before release.</li> <li>Versioning:   Uses <code>./scripts/get-version.sh</code> to determine the release version.</li> <li>Release creation:   Runs <code>gh release create v&lt;version&gt; ./dist/* --generate-notes</code> to publish a new GitHub Release with attached artifacts.</li> </ul> <p>Usage:</p> <p>To execute the release script, use the following command in the terminal:</p> <pre><code>./release.sh [-b|--build]\n</code></pre> <p>Examples:</p> <ul> <li>To create a release using existing build artifacts: <code>./release.sh</code></li> <li>To build the project first, then create the release: <code>./release.sh -b</code></li> </ul> <p>Notes:</p> <ul> <li>A .env file is optional but will be loaded if present.</li> <li>The dist/ directory must contain the build artifacts before release.</li> <li>The release tag will be prefixed with v (e.g., v1.2.3).</li> </ul>","tags":["dev","development","scripts"]},{"location":"dev/scripts/test.sh/","title":"\ud83e\uddea test.sh","text":"<p>This script is used to run the pytest tests for the project.</p> <p>The script performs the following operations:</p> <ul> <li>Running pytest: Runs the pytest tests for the project.</li> <li>Logging: If the <code>-l</code> or <code>--log</code> option is provided, the script will log the output of the pytest tests to console.</li> <li>Coverage: If the <code>-c</code> or <code>--cov</code> option is provided, the script will run the pytest tests with coverage.</li> <li>Verbose: If the <code>-v</code> or <code>--verbose</code> option is provided, the script will run the pytest tests with verbose error outputs.</li> </ul> <p>Usage:</p> <p>To execute the test script, simply run the following command in the terminal:</p> <pre><code>./test.sh [-l|--log] [-c|--cov] [-v|--verbose]\n</code></pre> <p>Examples:</p> <ul> <li>To test: <code>./test.sh</code></li> <li>To test with logging: <code>./test.sh -l</code></li> <li>To test with coverage: <code>./test.sh -c</code></li> <li>To test with verbose: <code>./test.sh -v</code></li> <li>To test with logging, coverage and verbose: <code>./test.sh -l -c -v</code></li> </ul> <p>This script will run the pytest tests for the project. It can also be used to run the tests with logging, coverage, and verbose options.</p>","tags":["dev","development","scripts"]},{"location":"dev/scripts/test.sh/#references","title":"References","text":"<ul> <li>https://docs.pytest.org</li> </ul>","tags":["dev","development","scripts"]},{"location":"getting-started/configuration/","title":"\u2699\ufe0f Configuration","text":"<p><code>templates/configs/logger.yml</code>:</p> <pre><code>logger:\n  # app_name: \"app\"\n  level: \"INFO\"\n  use_diagnose: false\n  stream:\n    use_color: true\n    use_icon: false\n    format_str: \"[&lt;c&gt;{time:YYYY-MM-DD HH:mm:ss.SSS Z}&lt;/c&gt; | &lt;level&gt;{level_short:&lt;5}&lt;/level&gt; | &lt;w&gt;{name}:{line}&lt;/w&gt;]: &lt;level&gt;{message}&lt;/level&gt;\"\n    std_handler:\n      enabled: true\n  file:\n    logs_dir: \"./logs\"\n    rotate_size: 10000000 # 10MB\n    rotate_time: \"00:00:00\"\n    backup_count: 90\n    log_handlers:\n      enabled: false\n      format_str: \"[{time:YYYY-MM-DD HH:mm:ss.SSS Z} | {level_short:&lt;5} | {name}:{line}]: {message}\"\n      log_path: \"{app_name}.std.all.log\"\n      err_path: \"{app_name}.std.err.log\"\n    json_handlers:\n      enabled: false\n      use_custom: false\n      log_path: \"{app_name}.json.all.log\"\n      err_path: \"{app_name}.json.err.log\"\n  intercept:\n    auto_load:\n      enabled: true\n      only_base: false\n      ignore_modules: []\n    include_modules: []\n    mute_modules: []\n  extra:\n</code></pre>","tags":["getting-started"]},{"location":"getting-started/configuration/#environment-variables","title":"\ud83c\udf0e Environment Variables","text":"<p><code>.env.example</code>:</p> <pre><code># ENV=LOCAL\n# DEBUG=false\n# TZ=UTC\n\n# BEANS_LOGGING_DISABLE_DEFAULT=false\n# BEANS_LOGGING_CONFIG_PATH=\"./configs/logger.yml\"\n# BEANS_LOGGING_LOGS_DIR=\"./logs\"\n</code></pre>","tags":["getting-started"]},{"location":"getting-started/examples/","title":"\ud83d\udeb8 Examples","text":"","tags":["getting-started"]},{"location":"getting-started/examples/#simple","title":"Simple","text":"<p><code>examples/simple/main.py</code>:</p> <pre><code>#!/usr/bin/env python\n\nfrom beans_logging.auto import logger\n\n\nlogger.trace(\"Tracing...\")\nlogger.debug(\"Debugging...\")\nlogger.info(\"Logging info.\")\nlogger.success(\"Success.\")\nlogger.warning(\"Warning something.\")\nlogger.error(\"Error occured.\")\nlogger.critical(\"CRITICAL ERROR.\")\n\n\ndef divide(a, b):\n    _result = a / b\n    return _result\n\n\ndef nested(c):\n    try:\n        divide(5, c)\n    except ZeroDivisionError as err:\n        logger.error(err)\n        raise\n\n\ntry:\n    nested(0)\nexcept Exception:\n    logger.exception(\"Show me, what value is wrong:\")\n</code></pre>","tags":["getting-started"]},{"location":"getting-started/installation/","title":"\ud83d\udee0 Installation","text":"","tags":["getting-started"]},{"location":"getting-started/installation/#1-download-or-clone-the-repository","title":"1. \ud83d\udce5 Download or clone the repository","text":"<p>[TIP] Skip this step, if you're going to install the package directly from PyPi or GitHub repository.</p> <p>1.1. Prepare projects directory (if not exists):</p> <pre><code># Create projects directory:\nmkdir -pv ~/workspaces/projects\n\n# Enter into projects directory:\ncd ~/workspaces/projects\n</code></pre> <p>1.2. Follow one of the below options [A], [B] or [C]:</p> <p>OPTION A. Clone the repository:</p> <pre><code>git clone https://github.com/bybatkhuu/module-python-logging.git &amp;&amp; \\\n    cd module-python-logging\n</code></pre> <p>OPTION B. Clone the repository (for DEVELOPMENT: git + ssh key):</p> <pre><code>git clone git@github.com:bybatkhuu/module-python-logging.git &amp;&amp; \\\n    cd module-python-logging\n</code></pre> <p>OPTION C. Download source code:</p> <ol> <li>Download archived zip file from releases.</li> <li>Extract it into the projects directory.</li> </ol>","tags":["getting-started"]},{"location":"getting-started/installation/#2-install-the-package","title":"2. \ud83d\udce6 Install the package","text":"<p>[NOTE] Choose one of the following methods to install the package [A ~ F]:</p> <p>OPTION A. [RECOMMENDED] Install from PyPi:</p> <pre><code>pip install -U beans-logging\n</code></pre> <p>OPTION B. Install latest version directly from GitHub repository:</p> <pre><code>pip install git+https://github.com/bybatkhuu/module-python-logging.git\n</code></pre> <p>OPTION C. Install from the downloaded source code:</p> <pre><code># Install directly from the source code:\npip install .\n\n# Or install with editable mode:\npip install -e .\n</code></pre> <p>OPTION D. Install for DEVELOPMENT environment:</p> <pre><code>pip install -e .[dev]\n\n# Install pre-commit hooks:\npre-commit install\n</code></pre> <p>OPTION E. Install from pre-built release files:</p> <ol> <li>Download <code>.whl</code> or <code>.tar.gz</code> file from releases</li> <li>Install with pip:</li> </ol> <pre><code># Install from .whl file:\npip install ./beans_logging-[VERSION]-py3-none-any.whl\n\n# Or install from .tar.gz file:\npip install ./beans_logging-[VERSION].tar.gz\n</code></pre> <p>OPTION F. Copy the module into the project directory (for testing):</p> <pre><code># Install python dependencies:\npip install -r ./requirements.txt\n\n# Copy the module source code into the project:\ncp -r ./src/beans_logging [PROJECT_DIR]\n# For example:\ncp -r ./src/beans_logging /some/path/project/\n</code></pre>","tags":["getting-started"]},{"location":"getting-started/prerequisites/","title":"\ud83d\udea7 Prerequisites","text":"<ul> <li>Install Python (&gt;= v3.10) and pip (&gt;= 23):<ul> <li>[RECOMMENDED]  Miniconda (v3)</li> <li>[arm64/aarch64]  Miniforge (v3)</li> <li>[Python virutal environment]  venv</li> </ul> </li> </ul> <p>[OPTIONAL] For DEVELOPMENT environment:</p> <ul> <li>Install git</li> <li>Setup an SSH key</li> </ul>","tags":["getting-started"]}]}